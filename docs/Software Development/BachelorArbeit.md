---
sidebar_position: 1
---

# Bachelor Arbeit

Prof. Dr. Frank Weichert

Preboarding-ChatBot fuer TU-Dortmund Webseite

# ChatGPT

Generative pretrained transformer
LLM
175 milliarden parameter
96 schichten input layer

1. Model Evaluation and Deployment
2. Training Techniques and Optimizations
3. Language Generation and Understanding
4. Machine Learning Infrastructure and Operations
5. Neural Network Architecture and Components

### Wie es von der Frage zur Antwort kommt

ChatGPT besteht aus einem tiefen neuronalen Netzwerk, das auf der GPT-3.5-Architektur von OpenAI basiert. Das Modell wurde mit riesigen Mengen an Textdaten trainiert, um eine breite Palette von natürlicher Sprache zu verstehen und darauf zu reagieren. Hier sind die grundlegenden Schritte, die bei der Erstellung einer Antwort durch ChatGPT durchgeführt werden:

1. **Tokenisierung:** Die Eingabe wird in kleinere Einheiten, sogenannte Tokens, aufgeteilt. Ein Token könnte beispielsweise ein einzelnes Zeichen oder eine Gruppe von Zeichen sein. Dies ermöglicht dem Modell, den Text in handhabbare Teile zu zerlegen.

2. **Embedding:** Jedes Token wird in einen numerischen Vektor umgewandelt, der das semantische Verständnis des Tokens repräsentiert. Diese Vektoren werden als Embeddings bezeichnet und helfen dem Modell, den Kontext der Wörter zu verstehen.

3. **Verarbeitung durch das Modell:** Die eingebetteten Tokens werden dem tiefen neuronalen Netzwerk von GPT-3.5 zugeführt. Das Modell hat während des Trainings gelernt, komplexe Muster und Abhängigkeiten in den Daten zu erfassen. Es verwendet diese Fähigkeiten, um den Kontext der Eingabe zu verstehen.

4. **Generierung der Antwort:** Basierend auf dem gelernten Kontext generiert das Modell eine Antwort. Dabei versucht es, kohärente und sinnvolle Sätze zu bilden, die auf die Eingabe bezogen sind.

5. **Dekodierung:** Die generierte Antwort wird wieder in natürliche Sprache umgewandelt und als Textausgabe präsentiert.

Es ist wichtig zu beachten, dass ChatGPT auf bereits vorhandenem Texttraining basiert und keine echte Verständnis- oder Bewusstseinsfähigkeit hat. Es zieht lediglich Schlüsse aus Mustern in den Daten, auf denen es trainiert wurde. Daher kann es in manchen Fällen fehlerhaft sein oder nicht vollständig den Kontext erfassen.

---
# Bachelor Thesis

Prof. Dr. Frank Weichert

Preboarding ChatBot for TU Dortmund Website

# ChatGPT

Generative Pretrained Transformer
GPT-3.5
175 billion parameters
96 layers input layer

1. Model Evaluation and Deployment
2. Training Techniques and Optimizations
3. Language Generation and Understanding
4. Machine Learning Infrastructure and Operations
5. Neural Network Architecture and Components

### How it Goes from Question to Answer

ChatGPT consists of a deep neural network based on the GPT-3.5 architecture by OpenAI. The model has been trained on vast amounts of text data to understand and respond to a wide range of natural language. Here are the basic steps involved in generating a response by ChatGPT:

1. **Tokenization:** The input is divided into smaller units called tokens. A token could be a single character or a group of characters. This allows the model to break down the text into manageable pieces.

2. **Embedding:** Each token is converted into a numerical vector representing the semantic understanding of the token. These vectors are called embeddings and help the model understand the context of the words.

3. **Processing by the Model:** The embedded tokens are fed into the deep neural network of GPT-3.5. During training, the model has learned to capture complex patterns and dependencies in the data. It uses these abilities to understand the context of the input.

4. **Generation of the Response:** Based on the learned context, the model generates a response, attempting to form coherent and meaningful sentences relevant to the input.

5. **Decoding:** The generated response is converted back into natural language and presented as text output.

It's important to note that ChatGPT is based on pre-existing text training and does not have genuine understanding or consciousness. It merely draws inferences from patterns in the data it was trained on. Therefore, it may be erroneous or not fully grasp the context in some cases.
